{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a collection of observations around why MIDI is not training well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "/notebooks/MusicTransformer-tensorflow2.0\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks/MusicTransformer-tensorflow2.0\n"
     ]
    }
   ],
   "source": [
    "%cd /notebooks/MusicTransformer-tensorflow2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Comparing Datasets\n",
    "\n",
    "I first worked through the local GPU issues, and then set it up to train `classic_piano` in comparison to `midi`. I graphed the metrics through Tensorboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import train\n",
    "train(\n",
    "    '/data/classic_piano_preprocessed',\n",
    "    './save',\n",
    "    log_dir='/tmp/logs/classic_piano_preprocessed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import train\n",
    "train(\n",
    "    '../out/transformer-preprocess',\n",
    "    './save-transformer-preprocess',\n",
    "    log_dir='/tmp/logs/transformer-preprocess'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a graph of the accuracy, with `classic_piano` through ~65 epochs and `midi` through ~20 epochs. `classic_piano` is clearly on the upswing, and looks [comparable in slope to the results in the original repo](https://github.com/jason9693/MusicTransformer-tensorflow2.0#result).\n",
    "\n",
    "`midi` is going nowhere fast (which is why I stopped it early).\n",
    "\n",
    "![Accuracy](./accuracy.png)\n",
    "\n",
    "Here's a graph of the loss. The loss for `midi` stays at 0.\n",
    "\n",
    "![Loss](./loss.png)\n",
    "\n",
    "The most likely culprit is that there's something wrong with the underlying data. So let's look at that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Examining the Data\n",
    "\n",
    "Let's log out the tensor information we're getting from each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Input path: /data/classic_piano_preprocessed\n",
      "batch_x\n",
      "(2, 1024)\n",
      "[[367  51 256 ... 304 163 361]\n",
      " [369  79 281 ...  75 366  60]]\n",
      "min tf.Tensor(27, shape=(), dtype=int64)\n",
      "max tf.Tensor(380, shape=(), dtype=int64)\n",
      "mean tf.Tensor(218, shape=(), dtype=int64)\n",
      "batch_y\n",
      "(2, 1024)\n",
      "[[ 51 256 168 ... 163 361  40]\n",
      " [ 79 281 179 ... 366  60 308]]\n",
      "min tf.Tensor(27, shape=(), dtype=int64)\n",
      "max tf.Tensor(380, shape=(), dtype=int64)\n",
      "mean tf.Tensor(218, shape=(), dtype=int64)\n",
      "\n",
      "\n",
      "Input path: ../out/transformer-preprocess\n",
      "batch_x\n",
      "(2, 1024)\n",
      "[[390. 388. 388. ... 388. 388. 388.]\n",
      " [390. 388. 388. ... 388. 388. 388.]]\n",
      "min tf.Tensor(388.0, shape=(), dtype=float64)\n",
      "max tf.Tensor(390.0, shape=(), dtype=float64)\n",
      "mean tf.Tensor(388.001953125, shape=(), dtype=float64)\n",
      "batch_y\n",
      "(2, 1024)\n",
      "[[388. 388. 388. ... 388. 388. 388.]\n",
      " [388. 388. 388. ... 388. 388. 388.]]\n",
      "min tf.Tensor(388.0, shape=(), dtype=float64)\n",
      "max tf.Tensor(388.0, shape=(), dtype=float64)\n",
      "mean tf.Tensor(388.0, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "from data import Data\n",
    "import tensorflow as tf\n",
    "\n",
    "batch_size = 2\n",
    "max_seq = 1024\n",
    "\n",
    "input_paths = [\n",
    "    '/data/classic_piano_preprocessed',\n",
    "    '../out/transformer-preprocess',    \n",
    "]\n",
    "\n",
    "for input_path in input_paths:\n",
    "    print('\\n\\nInput path: {}'.format(input_path))\n",
    "    dataset = Data(input_path)\n",
    "    batch_x, batch_y = dataset.slide_seq2seq_batch(batch_size, max_seq)\n",
    "    print('batch_x')\n",
    "    print(batch_x.shape)\n",
    "    print(batch_x[0:5])\n",
    "    print('min', tf.math.reduce_min(batch_x, axis=None, keepdims=False, name=None))\n",
    "    print('max', tf.math.reduce_max(batch_x, axis=None, keepdims=False, name=None))\n",
    "    print('mean', tf.math.reduce_mean(batch_x, axis=None, keepdims=False, name=None))\n",
    "    print('batch_y')\n",
    "    print(batch_y.shape)\n",
    "    print(batch_y)\n",
    "    print('min', tf.math.reduce_min(batch_y, axis=None, keepdims=False, name=None))\n",
    "    print('max', tf.math.reduce_max(batch_y, axis=None, keepdims=False, name=None))\n",
    "    print('mean', tf.math.reduce_mean(batch_y, axis=None, keepdims=False, name=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shapes of each tensor batch are identical, but the data is pretty different. For `classic_piano`, there's a pretty wide range of values (27-380), but for `midi`, they all seem to fall in a small band (`388-390`).\n",
    "\n",
    "That seems pretty suspicious."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Preprocessing MIDI step\n",
    "\n",
    "Next let's see how the data is being preprocessed by in the original repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the classic_piano dataset\n",
    "\n",
    "!sh /notebooks/MusicTransformer-tensorflow2.0/dataset/scripts/classic_piano_downloader.sh /data/classic_piano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in pachctl-interaction\n",
    "# get.py --repo midi --out ../musictransformer/dev/out\n",
    "# !mv ../src/out ../out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "329 files in classic_piano\n",
      "156 files in MIDI\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "CLASSIC_PIANO_DATA = '/data/classic_piano'\n",
    "MIDI = '../out/midi'\n",
    "\n",
    "print('{} files in {}'.format(len(os.listdir(CLASSIC_PIANO_DATA)), 'classic_piano'))\n",
    "print('{} files in {}'.format(len(os.listdir(MIDI)), 'MIDI'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an aside, the sample dataset has 329 files, while we have 156; but I'm not sure how best to compare the lengths of the files. It may be worth measuring more definitively how our dataset compares to `classic_piano` or one of the other sample ones.\n",
    "\n",
    "We can try running `preprocess` on the different datasets and see if anything jumps out as being fishy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocess.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MIDI Paths in /data/classic_piano: 100%|██████████| 329/329 [00:35<00:00,  9.37it/s]\n",
      "MIDI Paths in ../out/midi: 100%|██████████| 156/156 [00:16<00:00,  9.34it/s]\n"
     ]
    }
   ],
   "source": [
    "from preprocess import preprocess_midi_files_under_original\n",
    "\n",
    "preprocess_midi_files_under_original(CLASSIC_PIANO_DATA, '/tmp/data/classic_piano_preprocessed')\n",
    "preprocess_midi_files_under_original(MIDI, '/tmp/data/midi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything seems legit. Let's try pre-processing individual files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import preprocess_midi_original\n",
    "import os\n",
    "\n",
    "def printPreprocessedData(file):\n",
    "    print(file)\n",
    "    print(preprocess_midi_original(file)[0:20])\n",
    "\n",
    "classic_piano_data = ['{folder}/{file}'.format(folder=CLASSIC_PIANO_DATA, file=file) for file in os.listdir(CLASSIC_PIANO_DATA)]\n",
    "midi_data = [os.path.abspath('{folder}/{file}'.format(folder=MIDI, file=file)) for file in os.listdir(MIDI)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/classic_piano/schuim-4_format0.mid\n",
      "[366, 83, 366, 44, 265, 364, 87, 211, 264, 366, 83, 172, 264, 364, 80, 265, 208, 366, 80, 366]\n"
     ]
    }
   ],
   "source": [
    "printPreprocessedData(classic_piano_data[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks/out/midi/liquidmind-10-thejoyofquietpt2.wav.mid\n",
      "[]\n",
      "/notebooks/out/midi/gas-03-nach1912.wav.mid\n",
      "[]\n",
      "/notebooks/out/midi/easternawakening-14-hillsofnepal.wav.mid\n",
      "[]\n",
      "/notebooks/out/midi/rudyadrian-06-thelegendofkristylynn.wav.mid\n",
      "[]\n",
      "/notebooks/out/midi/deuter-05-thesource.wav.mid\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 5):\n",
    "    printPreprocessedData(midi_data[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very interesting! So what jumps out here is that the `MIDI` files are being pre-processed as empty arrays. This would go a good way towards explaining why the incoming tensors in the training step look so fishy.\n",
    "\n",
    "Why are they failing to be preprocessed? Let's crack open `midi_processor` and see what `encode_midi` is doing. Below is a reproduction of some of the code from the original `midi_processor/processor.py` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pretty_midi\n",
    "\n",
    "midi_file_one = pretty_midi.PrettyMIDI(midi_file=midi_data[0])\n",
    "piano_file_one = pretty_midi.PrettyMIDI(midi_file=classic_piano_data[0])\n",
    "\n",
    "from midi_processor.processor import _control_preprocess, _note_preprocess, _divide_note, _make_time_sift_events, _snote2events\n",
    "\n",
    "def _note_preprocess_jupyter(susteins, notes):\n",
    "    note_stream = []\n",
    "\n",
    "    for sustain in susteins:\n",
    "        for note_idx, note in enumerate(notes):\n",
    "            if note.start < sustain.start:\n",
    "                note_stream.append(note)\n",
    "            elif note.start > sustain.end:\n",
    "                notes = notes[note_idx:]\n",
    "                sustain.transposition_notes()\n",
    "                break\n",
    "            else:\n",
    "                sustain.add_managed_note(note)\n",
    "\n",
    "    for sustain in susteins:\n",
    "        note_stream += sustain.managed_notes\n",
    "\n",
    "    note_stream.sort(key= lambda x: x.start)\n",
    "    return note_stream\n",
    "\n",
    "def encode_midi_jupyter(file_path):\n",
    "    events = []\n",
    "    notes = []\n",
    "    mid = pretty_midi.PrettyMIDI(midi_file=file_path)\n",
    "\n",
    "    for inst in mid.instruments:\n",
    "        inst_notes = inst.notes\n",
    "        # ctrl.number is the number of sustain control. If you want to know abour the number type of control,\n",
    "        # see https://www.midi.org/specifications-old/item/table-3-control-change-messages-data-bytes-2\n",
    "        ctrls = _control_preprocess([ctrl for ctrl in inst.control_changes if ctrl.number == 64])\n",
    "        notes += _note_preprocess(ctrls, inst_notes)\n",
    "\n",
    "    dnotes = _divide_note(notes)\n",
    "\n",
    "    # print(dnotes)\n",
    "    dnotes.sort(key=lambda x: x.time)\n",
    "    # print('sorted:')\n",
    "    # print(dnotes)\n",
    "    cur_time = 0\n",
    "    cur_vel = 0\n",
    "    for snote in dnotes:\n",
    "        events += _make_time_sift_events(prev_time=cur_time, post_time=snote.time)\n",
    "        events += _snote2events(snote=snote, prev_vel=cur_vel)\n",
    "        # events += _make_time_sift_events(prev_time=cur_time, post_time=snote.time)\n",
    "\n",
    "        cur_time = snote.time\n",
    "        cur_vel = snote.velocity\n",
    "\n",
    "    return [e.to_int() for e in events]\n",
    "\n",
    "def printEncodedMIDIJupyter(file):\n",
    "    print(file)\n",
    "    print(encode_midi_jupyter(file)[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/classic_piano/scn15_7_format0.mid\n",
      "[355, 335, 368, 60, 330, 188, 367, 41, 370, 65, 355, 305, 362, 53, 362, 60, 361, 57, 361, 48]\n"
     ]
    }
   ],
   "source": [
    "printEncodedMIDIJupyter(classic_piano_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks/out/midi/liquidmind-10-thejoyofquietpt2.wav.mid\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "printEncodedMIDIJupyter(midi_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What appears to be happening is that the pre-processing step excepts the MIDI files to contain sustain notes. Our dataset has no sustain notes.\n",
    "\n",
    "Let's try and return the raw notes, _if_ no sustain notes are found:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pretty_midi\n",
    "\n",
    "midi_file_one = pretty_midi.PrettyMIDI(midi_file=midi_data[0])\n",
    "piano_file_one = pretty_midi.PrettyMIDI(midi_file=classic_piano_data[0])\n",
    "\n",
    "from midi_processor.processor import _control_preprocess, _note_preprocess, _divide_note, _make_time_sift_events, _snote2events\n",
    "\n",
    "def _note_preprocess_jupyter(susteins, notes):\n",
    "    note_stream = []\n",
    "\n",
    "    for sustain in susteins:\n",
    "        for note_idx, note in enumerate(notes):\n",
    "            if note.start < sustain.start:\n",
    "                note_stream.append(note)\n",
    "            elif note.start > sustain.end:\n",
    "                notes = notes[note_idx:]\n",
    "                sustain.transposition_notes()\n",
    "                break\n",
    "            else:\n",
    "                sustain.add_managed_note(note)\n",
    "\n",
    "    for sustain in susteins:\n",
    "        note_stream += sustain.managed_notes\n",
    "\n",
    "    note_stream.sort(key= lambda x: x.start)\n",
    "    return note_stream\n",
    "\n",
    "def encode_midi_jupyter(file_path):\n",
    "    events = []\n",
    "    notes = []\n",
    "    mid = pretty_midi.PrettyMIDI(midi_file=file_path)\n",
    "\n",
    "    for inst in mid.instruments:\n",
    "        inst_notes = inst.notes\n",
    "        # ctrl.number is the number of sustain control. If you want to know abour the number type of control,\n",
    "        # see https://www.midi.org/specifications-old/item/table-3-control-change-messages-data-bytes-2\n",
    "        ctrls_for_preprocessing = [ctrl for ctrl in inst.control_changes if ctrl.number == 64]\n",
    "        if len(ctrls_for_preprocessing) > 0:\n",
    "            ctrls = _control_preprocess(ctrls_for_preprocessing)\n",
    "            notes += _note_preprocess(ctrls, inst_notes)\n",
    "        else:\n",
    "            notes = inst_notes\n",
    "\n",
    "    dnotes = _divide_note(notes)\n",
    "\n",
    "    dnotes.sort(key=lambda x: x.time)\n",
    "    cur_time = 0\n",
    "    cur_vel = 0\n",
    "    for snote in dnotes:\n",
    "        events += _make_time_sift_events(prev_time=cur_time, post_time=snote.time)\n",
    "        events += _snote2events(snote=snote, prev_vel=cur_vel)\n",
    "\n",
    "        cur_time = snote.time\n",
    "        cur_vel = snote.velocity\n",
    "\n",
    "    return [e.to_int() for e in events]\n",
    "\n",
    "def printEncodedMIDIJupyter(file):\n",
    "    print(file)\n",
    "    print(encode_midi_jupyter(file)[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks/out/midi/liquidmind-10-thejoyofquietpt2.wav.mid\n",
      "[261, 361, 55, 261, 362, 60, 268, 183, 362, 55, 361, 52, 268, 188, 362, 60, 258, 183, 363, 55]\n"
     ]
    }
   ],
   "source": [
    "printEncodedMIDIJupyter(midi_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're getting data! Let's walk it back up the chain and try preprocessing our data with the fix that handles empty sustain notes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import preprocess_midi\n",
    "import os\n",
    "\n",
    "def printPreprocessedData(file):\n",
    "    print(file)\n",
    "    print(preprocess_midi(file)[0:2])    \n",
    "\n",
    "classic_piano_data = ['{folder}/{file}'.format(folder=CLASSIC_PIANO_DATA, file=file) for file in os.listdir(CLASSIC_PIANO_DATA)]\n",
    "midi_data = [os.path.abspath('{folder}/{file}'.format(folder=MIDI, file=file)) for file in os.listdir(MIDI)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/classic_piano/schuim-4_format0.mid\n",
      "[366, 83]\n"
     ]
    }
   ],
   "source": [
    "printPreprocessedData(classic_piano_data[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks/out/midi/liquidmind-10-thejoyofquietpt2.wav.mid\n",
      "[261, 361, 55, 261, 362, 60, 268, 183, 362, 55, 361, 52, 268, 188, 362, 60, 258, 183, 363, 55]\n"
     ]
    }
   ],
   "source": [
    "printEncodedMIDIJupyter(midi_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now a single file is being processed correctly. Let's try the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MIDI Paths: 100%|██████████| 329/329 [00:36<00:00,  9.04it/s]\n",
      "MIDI Paths: 100%|██████████| 156/156 [00:26<00:00,  5.89it/s]\n"
     ]
    }
   ],
   "source": [
    "from preprocess import preprocess_midi_files_under\n",
    "\n",
    "preprocess_midi_files_under(CLASSIC_PIANO_DATA, '/tmp/data/classic_piano_preprocessed')\n",
    "preprocess_midi_files_under(MIDI, '/tmp/data/midi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Input path: /tmp/data/classic_piano_preprocessed\n",
      "batch_x\n",
      "(2, 1024)\n",
      "[[256 368  45 ... 371  73 213]\n",
      " [372  64 369 ... 257 178 264]]\n",
      "min tf.Tensor(33, shape=(), dtype=int64)\n",
      "max tf.Tensor(377, shape=(), dtype=int64)\n",
      "mean tf.Tensor(221, shape=(), dtype=int64)\n",
      "batch_y\n",
      "(2, 1024)\n",
      "[[368  45 256 ...  73 213 376]\n",
      " [ 64 369  60 ... 178 264 364]]\n",
      "min tf.Tensor(33, shape=(), dtype=int64)\n",
      "max tf.Tensor(377, shape=(), dtype=int64)\n",
      "mean tf.Tensor(221, shape=(), dtype=int64)\n",
      "\n",
      "\n",
      "Input path: /tmp/data/midi\n",
      "batch_x\n",
      "(2, 1024)\n",
      "[[183 364  50 ...  57 268 190]\n",
      " [366  59 369 ... 369  57 371]]\n",
      "min tf.Tensor(29, shape=(), dtype=int64)\n",
      "max tf.Tensor(374, shape=(), dtype=int64)\n",
      "mean tf.Tensor(216, shape=(), dtype=int64)\n",
      "batch_y\n",
      "(2, 1024)\n",
      "[[364  50 364 ... 268 190 367]\n",
      " [ 59 369  64 ...  57 371  60]]\n",
      "min tf.Tensor(29, shape=(), dtype=int64)\n",
      "max tf.Tensor(374, shape=(), dtype=int64)\n",
      "mean tf.Tensor(216, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "from data import Data\n",
    "import tensorflow as tf\n",
    "\n",
    "batch_size = 2\n",
    "max_seq = 1024\n",
    "\n",
    "input_paths = [\n",
    "    '/tmp/data/classic_piano_preprocessed',\n",
    "    '/tmp/data/midi',    \n",
    "]\n",
    "\n",
    "for input_path in input_paths:\n",
    "    print('\\n\\nInput path: {}'.format(input_path))\n",
    "    dataset = Data(input_path)\n",
    "    batch_x, batch_y = dataset.slide_seq2seq_batch(batch_size, max_seq)\n",
    "    print('batch_x')\n",
    "    print(batch_x.shape)\n",
    "    print(batch_x[0:5])\n",
    "    print('min', tf.math.reduce_min(batch_x, axis=None, keepdims=False, name=None))\n",
    "    print('max', tf.math.reduce_max(batch_x, axis=None, keepdims=False, name=None))\n",
    "    print('mean', tf.math.reduce_mean(batch_x, axis=None, keepdims=False, name=None))\n",
    "    print('batch_y')\n",
    "    print(batch_y.shape)\n",
    "    print(batch_y)\n",
    "    print('min', tf.math.reduce_min(batch_y, axis=None, keepdims=False, name=None))\n",
    "    print('max', tf.math.reduce_max(batch_y, axis=None, keepdims=False, name=None))\n",
    "    print('mean', tf.math.reduce_mean(batch_y, axis=None, keepdims=False, name=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks much better! Let's give training a shot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import train\n",
    "train(\n",
    "    '/tmp/data/midi',\n",
    "    './save/midi',\n",
    "    log_dir='/tmp/logs/midi-preprocess'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These logs look much better; our training data appears to be tracking much closer to the `classic_piano` dataset:\n",
    "\n",
    "![New Accuracy](new-accuracy.png)\n",
    "\n",
    "Loss:\n",
    "\n",
    "![New Loss](new-loss.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
